dualencoder_name_or_path: /data1/linjk/work/prorec/save/CASP/cg-casp-moco-lmpa-c-only
dualencoder_subfolder: checkpoint-19500
asm_tokenizer_name_or_path: /data1/linjk/work/prorec/model/PurCL/longcodeart-ep0.3-block200-26m/checkpoint-25000
src_model_name_or_path: /data3/linjk/model/CodeLlama-13b-hf
# asm_feature_select_strategy: all
asm_feature_select_strategy: nodes
output_dir: /data1/linjk/work/prorec/save/allcg_src_prober_codellama-13b-last1unfreeze
hub_model_id: PurCL/src_prober_codellama-13b-last1unfreeze
dataset_name: ../data/bimodal-lmpa-shuffled-cg
run_name: prober-codellama-13b-last1unfreeze

max_seq_length: 256

max_eval_samples: 2000 # debug

per_device_train_batch_size: 8
gradient_accumulation_steps: 4
per_device_eval_batch_size: 16

dataloader_num_workers: 4
remove_unused_columns: false
do_train: true
do_eval: true
do_predict: false

overwrite_cache: false

# Training
num_train_epochs: 5
learning_rate: 0.00005
warmup_steps: 1000
weight_decay: 0.01
lr_scheduler_type: cosine
evaluation_strategy: steps
eval_steps: 500
save_steps: 500
logging_steps: 10
save_total_limit: 1

# Out
# report_to: wandb
cache_dir: ../save/.cache
push_to_hub: false
hub_private_repo: false
hub_strategy: all_checkpoints

overwrite_output_dir: true
# resume_from_checkpoint: true
torch_compile: false
fp16: true
# no_cuda: true